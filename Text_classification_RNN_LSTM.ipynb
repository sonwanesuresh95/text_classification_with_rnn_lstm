{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_content = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = file_content[['v2','v1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns = ['features', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset['features'],dataset['target'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize for word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode targets and convert to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lbl = LabelEncoder()\n",
    "lbl.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = lbl.transform(y_train)\n",
    "y_test = lbl.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(np.asarray(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(np.asarray(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train,maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pad_sequences(X_test,maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4457, 300), (1115, 300), (4457, 2), (1115, 2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=MAX_NB_WORDS, output_dim=EMB_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(5),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "    keras.layers.MaxPooling1D(5),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=128, activation='relu'),\n",
    "    keras.layers.Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "70/70 [==============================] - 14s 202ms/step - loss: 0.4467 - accuracy: 0.8115 - val_loss: 0.4704 - val_accuracy: 0.8673\n",
      "Epoch 2/5\n",
      "70/70 [==============================] - 16s 228ms/step - loss: 0.1893 - accuracy: 0.9289 - val_loss: 0.5854 - val_accuracy: 0.8673\n",
      "Epoch 3/5\n",
      "70/70 [==============================] - 14s 203ms/step - loss: 0.0877 - accuracy: 0.9764 - val_loss: 0.3469 - val_accuracy: 0.8673\n",
      "Epoch 4/5\n",
      "70/70 [==============================] - 14s 197ms/step - loss: 0.0565 - accuracy: 0.9852 - val_loss: 0.3225 - val_accuracy: 0.8673\n",
      "Epoch 5/5\n",
      "70/70 [==============================] - 14s 200ms/step - loss: 0.0399 - accuracy: 0.9906 - val_loss: 0.5285 - val_accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64 ,epochs=5, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       967\n",
      "           1       1.00      0.74      0.85       148\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1115\n",
      "   macro avg       0.98      0.87      0.91      1115\n",
      "weighted avg       0.97      0.97      0.96      1115\n",
      " samples avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=MAX_NB_WORDS, output_dim=EMB_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    keras.layers.SimpleRNN(units=2, input_shape=(-1,1)),\n",
    "    keras.layers.Dense(units=2,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 [==============================] - 12s 87ms/step - loss: 0.5304 - accuracy: 0.8690 - val_loss: 0.4258 - val_accuracy: 0.9130\n",
      "Epoch 2/5\n",
      "140/140 [==============================] - 12s 86ms/step - loss: 0.3089 - accuracy: 0.9576 - val_loss: 0.3289 - val_accuracy: 0.9202\n",
      "Epoch 3/5\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 0.1900 - accuracy: 0.9818 - val_loss: 0.2735 - val_accuracy: 0.9309\n",
      "Epoch 4/5\n",
      "140/140 [==============================] - 13s 91ms/step - loss: 0.1232 - accuracy: 0.9917 - val_loss: 0.2475 - val_accuracy: 0.9336\n",
      "Epoch 5/5\n",
      "140/140 [==============================] - 13s 93ms/step - loss: 0.0868 - accuracy: 0.9946 - val_loss: 0.2380 - val_accuracy: 0.9291\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       967\n",
      "           1       0.84      0.57      0.68       148\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1115\n",
      "   macro avg       0.89      0.78      0.82      1115\n",
      "weighted avg       0.93      0.93      0.92      1115\n",
      " samples avg       0.93      0.93      0.93      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=MAX_NB_WORDS, output_dim=EMB_DIM, input_length=MAX_SEQUENCE_LENGTH),\n",
    "    keras.layers.LSTM(units=2, activation='relu', return_sequences=True),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=2,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "279/279 [==============================] - 34s 123ms/step - loss: 0.2662 - accuracy: 0.8990 - val_loss: 0.1114 - val_accuracy: 0.9704\n",
      "Epoch 2/5\n",
      "279/279 [==============================] - 38s 137ms/step - loss: 0.0446 - accuracy: 0.9859 - val_loss: 0.0605 - val_accuracy: 0.9839\n",
      "Epoch 3/5\n",
      "279/279 [==============================] - 40s 142ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.0713 - val_accuracy: 0.9839\n",
      "Epoch 4/5\n",
      "279/279 [==============================] - 36s 128ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0666 - val_accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "279/279 [==============================] - 35s 124ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0952 - val_accuracy: 0.9848\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train, batch_size=16, epochs=5, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       967\n",
      "           1       0.99      0.89      0.94       148\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      1115\n",
      "   macro avg       0.99      0.95      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      " samples avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
